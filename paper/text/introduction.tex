
\section{Introduction}
\label{sec:introduction}

Despite advances in CPU speeds, memory size, and disk space, distributed systems still play an important role in the world of computing.  Individual computers are still not capable of handling many of the large data sets and complex computations required in computing today.  A distributed system, defined by Tanenbaum and Steen \cite{tanenbaum_text06} as ``a collection of independent computers that appears to its users as a single coherent system,'' unlocks the computing power of multiple computers and provides a logical abstraction to its users as a single entity.

One of the most basic challenges in building a distributed system involves data sharing.  There have been many implementations of data sharing in distributed environments, including distributed shared memory, remote object references, and distributed file systems.  It is the last approach, distributed file systems, that SPOOFS attempts to implement.  Distributed file systems ``allow multiple process to share data over long periods of time in a secure and reliable way'' \cite{tanenbaum_text06}.  This means that clients can access shared data in a distributed environment in a common way.

Two of the most important aspects of a distributed file system to consider are the data storage mechanism and data retrieval mechanism.  The first aspect, the data storage mechanism, answers the question ``How will the data be stored?''  A distributed system may require data storage needs that exceed a single computer.  Thus, distributed file systems often store data across multiple storage nodes.  A master node usually coordinates resource-allocation across the storage nodes and utilizes their disk space to store the files on the system.  A storage node in a distributed file system can either leverage an existing underlying file system (e.g. NTFS, ext3, etc.) or can create its own on-disk file system.  Concerns for consistency and fault tolerance of the data are often addressed through data replication.

The second aspect, the data retrieval mechanism, answers the question ``How can clients access the data?''  Presumably, an application will interact with a distributed file system similar to how it would interact with a local file system.  They expect operations to add/remove directories, add/remove files, and read/write file data.  It is important that a distributed file system expose a common interface to all clients, and that the interface expose the core functionality needed.  The major challenge with data retrieval in a distributed file system is locating the data.  In many distributed file systems, the master node is used as a central point of contact for clients.  The master helps locate and track files in the system.  Usually a call by a client to write data to a specific file will first require contact with the master to locate the file, then contact with the actual storage node to write the contents.

The issue of fault tolerance and partial failure is a major concern for many distributed systems \cite{waldo_note94}, and distributed file systems are no exception.  Each node in the system is a potential candidate for failure or partial failure and thus the system must be able to recover from such a failure to a usable state.  There are many possible models for failure in a distributed file system, including data corruption on the storage node, excess network traffic causing long delays, and client node crashes.  The failure model that we approached in SPOOFS is one in which the master node crashes or goes offline completely.  Though covering only a small portion of all possible failures, we believe that applying our model presents a good exercise in understanding the nature of fault tolerance in a distributed file system.
